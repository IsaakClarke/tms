{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a762d212-e8bf-483e-b383-cdfc171aadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9d711f-95a4-4a47-85d5-6899d56ff3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e89878d-d93d-45f5-a9c6-d7a5f24738c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", \"(Possibly corrupt EXIF data|Truncated File Read|load_weights) detected\", module=\"PIL.Image\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f0ade0-440a-46ab-a765-985a992826f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download('bhavikjikadara/dog-and-cat-classification-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d171568-ce1b-4120-ba40-b39c65252351",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(dataset_path, 'PetImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b1aac9-03e9-4bc0-a317-798cf9ae35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_and_clean_data(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_name, label_id in [('Cat', 0), ('Dog', 1)]:\n",
    "        path = os.path.join(root_dir, label_name)\n",
    "                \n",
    "        for filename in tqdm(os.listdir(path), desc=f\"Обработка {label_name}\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            \n",
    "            if not filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                \n",
    "                if img.mode not in ('RGB', 'L'):\n",
    "                    continue\n",
    "\n",
    "                image_paths.append(file_path)\n",
    "                labels.append(label_id)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    print(f\"total {len(labels)}\")\n",
    "    print(f\"cat {labels.count(0)}, dog {labels.count(1)}\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe7b05b-0b37-4e39-a57e-6b830999b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка Cat: 100%|███████████████████████████████████████████████████████████| 12499/12499 [00:09<00:00, 1291.74it/s]\n",
      "Обработка Dog: 100%|███████████████████████████████████████████████████████████| 12499/12499 [00:10<00:00, 1241.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24936\n",
      "cat 12473, dog 12463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_image_paths, all_labels = scan_and_clean_data(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb66624-8ed4-4428-af9d-758c11dd46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minclass4torch(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.placeholder_image = Image.new('RGB', (224, 224), color = 'black')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = self.placeholder_image\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832847fd-5779-4d1b-8747-a25b794da0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b5911f-8c0f-464d-9083-ac34cd3dc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), \n",
    "    transforms.ToTensor(),                       \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb7386f-3016-493d-8146-0d742cc67606",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = minclass4torch(all_image_paths, all_labels, transform=alexnet_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167de904-97f5-440d-8311-fe9f5a644840",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edbbf32-1df6-4d61-8fd1-e9551557102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2b12fea-6524-4204-b3e2-f7d741f78558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8751c8d-13e8-4641-99b9-51c7c7d6bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8151f0d3-99f5-4a41-8350-b94eba886cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eb91234-3819-4172-8304-05b0650945a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4cf3a8b-0cf4-4c37-be2b-b76a2ef805bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = alexnet_model.classifier[6].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aafe2202-88dc-4dfe-b35f-06989b64a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model.classifier[6] = nn.Linear(num_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eaaf5d7-ce02-417a-89cf-4be3755afbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "066f5b62-3e11-402e-b45b-e42c16a96a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adab4736-adef-4659-9627-4b3f5c96e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4 \n",
    "NUM_EPOCHS = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(alexnet_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "578a5eef-bcd6-4959-b306-b7f32cb509ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(loader, desc=\"train\")):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9b3225-34d2-461a-b721-7b204d68a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_f1_score(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Оценка\"):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            \n",
    "            _, predictions = scores.max(dim=1) \n",
    "            \n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            \n",
    "    f1 = f1_score(all_targets, all_preds, average='binary')\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    \n",
    "    model.train()\n",
    "    return f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b6c4ce9-0979-4d96-8e95-8c162c528cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:17<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6676, accuracy: 0.6173\n",
      "\n",
      "\n",
      "\n",
      "--- epoch 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 312/312 [01:27<00:00,  3.57it/s]\n",
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:16<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss per epoch: 0.1190\n",
      "accuracy on test: 0.9495\n",
      "F1 on test: 0.9465\n",
      "\n",
      "--- epoch 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 312/312 [01:26<00:00,  3.61it/s]\n",
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:16<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss per epoch: 0.0583\n",
      "accuracy on test: 0.9643\n",
      "F1 on test: 0.9630\n",
      "\n",
      "--- epoch 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 312/312 [01:25<00:00,  3.64it/s]\n",
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:16<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss per epoch: 0.0306\n",
      "accuracy on test: 0.9581\n",
      "F1 on test: 0.9588\n",
      "\n",
      "--- epoch 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 312/312 [01:26<00:00,  3.62it/s]\n",
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:17<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss per epoch: 0.0244\n",
      "accuracy on test: 0.9613\n",
      "F1 on test: 0.9615\n",
      "\n",
      "--- epoch 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████| 312/312 [01:26<00:00,  3.60it/s]\n",
      "Оценка: 100%|██████████████████████████████████████████████████████████████████████████| 78/78 [00:16<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss per epoch: 0.0229\n",
      "accuracy on test: 0.9669\n",
      "F1 on test: 0.9657\n",
      "total train time 517.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1_before, acc_before = check_f1_score(test_loader, alexnet_model, device)\n",
    "print(f\"F1: {f1_before:.4f}, accuracy: {acc_before:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\n--- epoch {epoch}/{NUM_EPOCHS} ---\")\n",
    "    \n",
    "    train_loss = train_epoch(\n",
    "        alexnet_model, \n",
    "        train_loader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        device\n",
    "    )\n",
    "    \n",
    "    f1_score_val, acc_val = check_f1_score(test_loader, alexnet_model, device)\n",
    "    \n",
    "    print(f\"avg loss per epoch: {train_loss:.4f}\")\n",
    "    print(f\"accuracy on test: {acc_val:.4f}\")\n",
    "    print(f\"F1 on test: {f1_score_val:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"total train time {total_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a28e08f0-96bd-45c6-b492-931ea6ffa36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Только начинается 2 эпоха, как я понимаю что это я некомпетентный и бездарный\n",
    "# Мои результаты с этими и рядом не стояли\n",
    "# Возможно получится догнать до 98-99 F1, и это уже не accuracy\n",
    "\n",
    "# Но, в прошлых попытках не было должной обработки, тут есть\n",
    "# И исходя из того, сколько варнингов за 50 минут я поймал, данные в cat vs dog не идеальные\n",
    "# тут не заморожены CNN слои, это full fine-tuning (чуть переучить свертку ради снижения overfitting'а на fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee458d5-0e18-472a-ac2e-6d4637bcce95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
