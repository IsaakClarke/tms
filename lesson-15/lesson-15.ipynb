{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbad6e85-114c-48f7-89a9-f9c756736c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сверточные нейросети (CNN)\n",
    "\n",
    "## 1. Что такое CNN\n",
    "# Сверточная нейросеть (Convolutional Neural Network) — это тип нейросети, оптимизированный для работы с данными, где важна пространственная структура (например, изображение, звук, видео, сигнал).\n",
    "\n",
    "# Главная идея — **извлечение признаков** через свертки (convolution), а не через полносвязные слои.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 2. Основные блоки CNN\n",
    "\n",
    "# Convolution (Conv2D) — фильтры, извлекающие признаки (края, текстуры, формы).  \n",
    "# Параметры: размер ядра (3×3, 5×5), шаг (stride), отступ (padding), количество фильтров.\n",
    "\n",
    "# Pooling (Max/Average) — уменьшает размерность, повышает устойчивость к сдвигам.  \n",
    "# Параметры: размер окна и шаг.\n",
    "\n",
    "# Activation (ReLU) — добавляет нелинейность, ускоряет обучение.  \n",
    "# Популярные функции: ReLU, LeakyReLU, GELU.\n",
    "\n",
    "# BatchNorm — стабилизирует распределение данных между слоями.  \n",
    "# Dropout — борется с переобучением, случайно \"выключая\" нейроны.  \n",
    "# Fully Connected (Dense) — заключительная часть, интерпретирует признаки и делает классификацию.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 3. Как обучается CNN\n",
    "# 1. Прямой проход (forward) — вычисляется предсказание.  \n",
    "# 2. Функция потерь (loss) — измеряет ошибку (часто CrossEntropy).  \n",
    "# 3. Обратное распространение (backpropagation) — корректирует веса.  \n",
    "# 4. Оптимизаторы: Adam, SGD, RMSProp.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 4. Ключевые архитектуры и их идеи\n",
    "\n",
    "### LeNet-5 (1998)\n",
    "# - Первая успешная CNN.\n",
    "# - Conv → Pool → Conv → Pool → FC → Softmax.\n",
    "# - Использовалась для распознавания цифр (MNIST).\n",
    "\n",
    "### AlexNet (2012)\n",
    "# - Прорыв на ImageNet.\n",
    "# - Использовала ReLU, Dropout и GPU-обучение.\n",
    "# - 5 сверток, 3 полносвязных слоя.\n",
    "\n",
    "### VGG16 / VGG19 (2014)\n",
    "# - Простая структура: блоки по 2–3 слоя 3×3 conv + pooling.\n",
    "# - Очень глубокая, легко расширяемая.\n",
    "# - Часто используется для feature extraction.\n",
    "\n",
    "### GoogLeNet / Inception (2014)\n",
    "# - В каждом блоке несколько параллельных сверток: 1×1, 3×3, 5×5.\n",
    "# - Объединение разных масштабов признаков (Inception module).\n",
    "\n",
    "### ResNet (2015)\n",
    "# - Добавлены skip connections (остаточные связи): x + F(x).\n",
    "# - Позволило обучать сети 100+ слоев без деградации.\n",
    "# - Базовая архитектура для современных моделей.\n",
    "\n",
    "### DenseNet (2016)\n",
    "# - Каждый слой получает на вход результаты всех предыдущих.\n",
    "# - Эффективное переиспользование признаков, меньше параметров.\n",
    "\n",
    "### MobileNet (2017)\n",
    "# - Легкая архитектура: depthwise + pointwise свертки.\n",
    "# - Разработана для мобильных и встроенных систем.\n",
    "\n",
    "### EfficientNet (2019)\n",
    "# - Масштабирование по трем осям (глубина, ширина, разрешение).\n",
    "# - Лучшая эффективность при меньших параметрах.\n",
    "\n",
    "### ConvNeXt (2022)\n",
    "# - CNN нового поколения, вдохновлена Vision Transformer.\n",
    "# - LayerNorm, большие ядра, простая структура, но SOTA-результаты.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 5. На чем обучали\n",
    "\n",
    "# - Dataset: ImageNet (1.2 млн изображений, 1000 классов).  \n",
    "# - Аппаратное обеспечение: GPU (NVIDIA V100 / A100).  \n",
    "# - Фреймворки: PyTorch, TensorFlow, Keras.  \n",
    "# - Loss-функция: CrossEntropy.  \n",
    "\n",
    "# ---\n",
    "\n",
    "## 6. Где используются CNN\n",
    "\n",
    "# - Компьютерное зрение: классификация, детекция (YOLO, Faster R-CNN), сегментация (U-Net).  \n",
    "# - Медицина: анализ рентгенов и МРТ.  \n",
    "# - Автопилоты: обработка видеопотока с камер.  \n",
    "# - Генеративные модели: GAN, Autoencoder.  \n",
    "# - Аудио и временные ряды: CNN по спектрограммам.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 7. Как использовать в PyTorch\n",
    "\n",
    "# import torchvision.models as models\n",
    "# import torch.nn as nn\n",
    "\n",
    "# model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# model.fc = nn.Linear(2048, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5956111-705d-4840-a982-254827a39e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a7e735-2cef-4709-abee-4940b4cf6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b27b612-29bc-497c-8a31-7cafdd1c9652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = torch.stack([img for img, _ in train_dataset], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db7c48f-7cb6-40ab-ac05-fa41ba802cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13066047430038452 0.30810782313346863\n"
     ]
    }
   ],
   "source": [
    "mean = all_data.mean()\n",
    "std = all_data.std()\n",
    "print(mean.item(), std.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8472fe6-766a-4bd7-ac21-cdfbbe0049da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337a9eea-8539-46a8-a872-7a5429da6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843e4a5b-b4b8-4b24-b7d0-b1010d3f6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f04523-6f8e-4f11-afa6-9dec48d96183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfabca55-a33a-44e9-89d3-c25e649bc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64*7*7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23da6275-d190-426c-89ee-513078d6db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec0f5aa4-48ec-4803-a9be-a56c4a2b2ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c91291d3-7546-4dfd-bcf6-144b92ff1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Loss: 0.1758, interval: 0:00:33.015572\n",
      "Epoch 2/6, Loss: 0.0529, interval: 0:01:06.796724\n",
      "Epoch 3/6, Loss: 0.0362, interval: 0:01:40.555701\n",
      "Epoch 4/6, Loss: 0.0275, interval: 0:02:14.209790\n",
      "Epoch 5/6, Loss: 0.0196, interval: 0:02:47.376155\n",
      "Epoch 6/6, Loss: 0.0173, interval: 0:03:20.664509\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "time = dt.now()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, interval: {dt.now() - time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3529875d-7146-4156-8cb9-b3ed12e573a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.14%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c260d9-fe06-40fa-908b-fbf0db367757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu118, 11.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.__version__}, {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c549357d-7394-4fcb-9400-09ead7bb726b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6da53e-e56a-41e7-a831-cfe923e1fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44dd572c-b837-4d30-a16b-4def75aff352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6, Loss: 0.0159, interval: 0:00:09.712307\n",
      "Epoch 2/6, Loss: 0.0105, interval: 0:00:19.606749\n",
      "Epoch 3/6, Loss: 0.0084, interval: 0:00:29.404310\n",
      "Epoch 4/6, Loss: 0.0084, interval: 0:00:39.145483\n",
      "Epoch 5/6, Loss: 0.0061, interval: 0:00:48.828008\n",
      "Epoch 6/6, Loss: 0.0065, interval: 0:00:58.494893\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6\n",
    "time = dt.now()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, interval: {dt.now() - time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd548eed-c9a2-4153-ae29-3e767067ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.16%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4ee008-85f3-4ff6-ab46-8635c76e91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так, наконец этот танец с бубном завершился\n",
    "# Видеокарта (моя) слишком древняя, чтобы запустить свежий toolkit, поэтому каскадно перебирал версии и в итоге:\n",
    "# numpy, torch, torchvision, torchaudio теперь старые\n",
    "# Исходя из результата, ~200сек (CPU) / ~58сек (GPU) - 1 = ~ 2.45 (245%) прироста скорости при вычислениях на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dd8b7ee-050a-4b7a-9f35-20fadc378108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительный Сверточный Слой (Convolutional Layer)\n",
    "\n",
    "# Сложно:\n",
    "# Добавление сверточных слоев повышает иерархическую глубину сети,\n",
    "# обеспечивая экстракцию более семантически богатых и композиционных признаков (compositional features).\n",
    "\n",
    "# Просто:\n",
    "# Делает модель \"умнее\" и позволяет ей распознавать более сложные концепции.\n",
    "# Например, если первый слой ищет линии, то более глубокий слой, используя эти линии, может найти формы, а еще более глубокий — объекты.\n",
    "# Увеличивает риск переобучения (overfitting), так как модель становится сложнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68d82a28-88c4-4de6-8530-db0b1c6c8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поллинг-слой (Pooling Layer)\n",
    "\n",
    "# Сложно:\n",
    "# Поллинг обеспечивает пространственную инвариантность (spatial invariance) и выполняет даунсэмплинг (downsampling) карт признаков,\n",
    "# тем самым снижая вычислительную нагрузку.\n",
    "\n",
    "# Просто:\n",
    "# Делает модель устойчивой к небольшим сдвигам и искажениям во входном изображении.\n",
    "# Модель фокусируется на наличии признака, а не на его точном местоположении, что улучшает обобщение (generalization) на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2a40b20-0103-4c0c-ab13-2f50a146df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Паддинг (Padding)\n",
    "\n",
    "# Сложно:\n",
    "# Паддинг контролирует сохранение пространственной размерности (spatial resolution) карт признаков после операции свертки,\n",
    "# предотвращая потерю информации с краев входного тензора.\n",
    "\n",
    "# Просто:\n",
    "# Сохраняет важную информацию по краям изображения.\n",
    "# Без паддинга края изображения быстро \"сжимаются\" и их данные игнорируются.\n",
    "# Паддинг помогает поддерживать стабильную геометрическую структуру сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bbd9be8-6a0d-42a3-8708-6b552f8e18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительный Полносвязный Слой (FC Layer)\n",
    "\n",
    "# Сложно:\n",
    "# Добавление FC-слоев увеличивает сложность пространства решений (decision boundary) на финальном этапе классификации\n",
    "# и усиливает нелинейность модели.\n",
    "\n",
    "# Просто:\n",
    "# Делает окончательное решение о классе более сложным и точным.\n",
    "# Преобразует извлеченные свертками абстрактные признаки в финальные вероятности классов.\n",
    "# Существенно увеличивает общее количество параметров модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
