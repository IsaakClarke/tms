{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6dd15e2-d7a5-4e3a-85cb-94fc4463da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f467513-9019-4a96-889b-cb47c7409ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, *, is_leaf=False, value=None, feat=None, thr=None, left=None, right=None, depth=0, n=0):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = value\n",
    "        self.feat = feat\n",
    "        self.thr = thr\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.n = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8f9187-c82c-4473-8413-1a2dbbf8ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_gain=0.0,\n",
    "                 task='classification', criterion='gini', max_features=None, random_state=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.task = task\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        self.n_feats = X.shape[1]\n",
    "        if self.task == 'classification':\n",
    "            self.classes = np.unique(y)\n",
    "        self.root = self._build(X, y, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _build(self, X, y, depth):\n",
    "        n, m = X.shape\n",
    "        node = Node(depth=depth, n=n)\n",
    "\n",
    "        if self._stop(y, depth):\n",
    "            node.is_leaf = True\n",
    "            node.value = self._leaf_value(y)\n",
    "            return node\n",
    "\n",
    "        feat, thr, gain = self._best_split(X, y)\n",
    "        if feat is None or gain < self.min_gain:\n",
    "            node.is_leaf = True\n",
    "            node.value = self._leaf_value(y)\n",
    "            return node\n",
    "\n",
    "        mask = X[:, feat] <= thr\n",
    "        X_left, y_left = X[mask], y[mask]\n",
    "        X_right, y_right = X[~mask], y[~mask]\n",
    "\n",
    "        node.feat = feat\n",
    "        node.thr = thr\n",
    "        node.left = self._build(X_left, y_left, depth + 1)\n",
    "        node.right = self._build(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _stop(self, y, depth):\n",
    "        if len(y) < self.min_samples_split:\n",
    "            return True\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return True\n",
    "        if self.task == 'classification':\n",
    "            return np.unique(y).size == 1\n",
    "        else:\n",
    "            return np.var(y) < 1e-9\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        if self.task == 'classification':\n",
    "            vals, cnts = np.unique(y, return_counts=True)\n",
    "            return vals[np.argmax(cnts)]\n",
    "        else:\n",
    "            return np.mean(y)\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        if self.task == 'classification':\n",
    "            vals, cnts = np.unique(y, return_counts=True)\n",
    "            p = cnts / len(y)\n",
    "            if self.criterion == 'gini':\n",
    "                return 1 - np.sum(p ** 2)\n",
    "            elif self.criterion == 'entropy':\n",
    "                p = p[p > 0]\n",
    "                return -np.sum(p * np.log2(p))\n",
    "        else:\n",
    "            return np.var(y)\n",
    "        return 0\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, m = X.shape\n",
    "        best_gain = 0\n",
    "        best_feat = None\n",
    "        best_thr = None\n",
    "        parent_imp = self._impurity(y)\n",
    "\n",
    "        feats = np.arange(m)\n",
    "        if self.max_features is not None:\n",
    "            if isinstance(self.max_features, float):\n",
    "                k = int(self.max_features * m)\n",
    "            else:\n",
    "                k = self.max_features\n",
    "            feats = self.rng.choice(m, k, replace=False)\n",
    "\n",
    "        for j in feats:\n",
    "            vals = np.unique(X[:, j])\n",
    "            if len(vals) <= 1:\n",
    "                continue\n",
    "            thresholds = (vals[:-1] + vals[1:]) / 2\n",
    "            for thr in thresholds:\n",
    "                mask = X[:, j] <= thr\n",
    "                if np.all(mask) or np.all(~mask):\n",
    "                    continue\n",
    "                y_l, y_r = y[mask], y[~mask]\n",
    "                imp_l, imp_r = self._impurity(y_l), self._impurity(y_r)\n",
    "                gain = parent_imp - (len(y_l)/n)*imp_l - (len(y_r)/n)*imp_r\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feat = j\n",
    "                    best_thr = thr\n",
    "        return best_feat, best_thr, best_gain\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return np.array([self._predict_row(x, self.root) for x in X])\n",
    "\n",
    "    def _predict_row(self, x, node):\n",
    "        while not node.is_leaf:\n",
    "            if x[node.feat] <= node.thr:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07dbddaa-fd98-449e-a7b1-c7f9998b9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=None, min_samples_split=2, min_gain=0.0,\n",
    "                 max_features=None, bootstrap=True, task='classification', criterion='gini', random_state=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.task = task\n",
    "        self.criterion = criterion\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        for i in range(self.n_trees):\n",
    "            idx = self.rng.choice(n, n, replace=True) if self.bootstrap else np.arange(n)\n",
    "            Xs, ys = X[idx], y[idx]\n",
    "\n",
    "            tree = DecisionTree(max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split,\n",
    "                                min_gain=self.min_gain,\n",
    "                                task=self.task,\n",
    "                                criterion=self.criterion,\n",
    "                                max_features=self.max_features,\n",
    "                                random_state=self.rng.randint(0, 1e6))\n",
    "            tree.fit(Xs, ys)\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.array([t.predict(X) for t in self.trees])\n",
    "        if self.task == 'classification':\n",
    "            final = []\n",
    "            for i in range(preds.shape[1]):\n",
    "                vals, cnts = np.unique(preds[:, i], return_counts=True)\n",
    "                final.append(vals[np.argmax(cnts)])\n",
    "            return np.array(final)\n",
    "        else:\n",
    "            return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138ee2a8-de75-49be-a18a-2e1edcce8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RandomForest Классификация ===\n",
      "Прогнозы: [0 0 1 1]\n",
      "\n",
      "=== RandomForest Регрессия ===\n",
      "Прогнозы: [ 0.2  0.6 10.  10.4]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0], [1], [2], [3], [4], [5]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "forest = RandomForest(n_trees=5, max_depth=2, task='classification', criterion='gini', random_state=42)\n",
    "forest.fit(X, y)\n",
    "\n",
    "print(\"=== RandomForest Классификация ===\")\n",
    "print(\"Прогнозы:\", forest.predict([[0], [1.5], [3.5], [5]]))\n",
    "\n",
    "Xr = np.array([[0], [1], [2], [3], [4], [5]])\n",
    "yr = np.array([0, 0, 1, 10, 11, 10])\n",
    "\n",
    "forest_r = RandomForest(n_trees=5, max_depth=2, task='regression', criterion='mse', random_state=42)\n",
    "forest_r.fit(Xr, yr)\n",
    "\n",
    "print(\"\\n=== RandomForest Регрессия ===\")\n",
    "print(\"Прогнозы:\", forest_r.predict([[0], [2], [3.5], [5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd8df44-5674-4e9c-85a1-443af4c3dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, \n",
    "                 min_samples_split=2, min_gain=0.0, max_features=None,\n",
    "                 task='regression', criterion='mse', random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.max_features = max_features\n",
    "        self.task = task\n",
    "        self.criterion = criterion\n",
    "        self.random_state = np.random.RandomState(random_state)\n",
    "        self.trees = []\n",
    "        self.init_pred = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        if self.task == 'regression':\n",
    "            self.init_pred = np.mean(y)\n",
    "            pred = np.full_like(y, self.init_pred, dtype=float)\n",
    "        else:\n",
    "            self.init_pred = np.log(np.mean(y) / (1 - np.mean(y)))\n",
    "            pred = np.full_like(y, self.init_pred, dtype=float)\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.task == 'regression':\n",
    "                residual = y - pred\n",
    "            else:\n",
    "                p = 1 / (1 + np.exp(-pred))\n",
    "                residual = y - p\n",
    "\n",
    "            tree = DecisionTree(max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split,\n",
    "                                min_gain=self.min_gain,\n",
    "                                task='regression',\n",
    "                                criterion='mse',\n",
    "                                max_features=self.max_features,\n",
    "                                random_state=self.random_state.randint(0, 1e6))\n",
    "            tree.fit(X, residual)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            update = tree.predict(X)\n",
    "            pred += self.learning_rate * update\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        n = X.shape[0]\n",
    "        pred = np.full(n, self.init_pred, dtype=float)\n",
    "\n",
    "        for tree in self.trees:\n",
    "            pred += self.learning_rate * tree.predict(X)\n",
    "\n",
    "        if self.task == 'regression':\n",
    "            return pred\n",
    "        else:\n",
    "            return (1 / (1 + np.exp(-pred))) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950e333c-9b46-4599-b6ea-2c365c76d228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GradientBoosting Регрессия ===\n",
      "Прогнозы: [ 0.06702857  0.06702857 10.00236848  9.99456021]\n",
      "\n",
      "=== GradientBoosting Классификация ===\n",
      "Прогнозы: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "Xr = np.array([[0], [1], [2], [3], [4], [5]])\n",
    "yr = np.array([0, 0, 1, 10, 11, 10])\n",
    "\n",
    "gb_r = GradientBoosting(n_estimators=20, learning_rate=0.2, max_depth=2, random_state=42)\n",
    "gb_r.fit(Xr, yr)\n",
    "\n",
    "print(\"=== GradientBoosting Регрессия ===\")\n",
    "print(\"Прогнозы:\", gb_r.predict([[0], [1.5], [3.5], [5]]))\n",
    "\n",
    "\n",
    "Xc = np.array([[0], [1], [2], [3], [4], [5]])\n",
    "yc = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "gb_c = GradientBoosting(n_estimators=10, learning_rate=0.5, max_depth=2, task='classification', random_state=42)\n",
    "gb_c.fit(Xc, yc)\n",
    "\n",
    "print(\"\\n=== GradientBoosting Классификация ===\")\n",
    "print(\"Прогнозы:\", gb_c.predict([[0], [1.5], [3.5], [5]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
